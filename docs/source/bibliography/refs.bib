@proceedings{Riemer2020,
abstract = {We explore the use of deep reinforcement learning to provide strategies for long term scheduling of hydropower production. We consider a use-case where the aim is to optimise the yearly revenue given week-by-week inflows to the reservoir and electricity prices. The challenge is to decide between immediate water release at the spot price of electricity and storing the water for later power production at an unknown price, given constraints on the system. We successfully train a soft actor-critic algorithm on a simplified scenario with historical data from the Nordic power market. The presented model is not ready to substitute traditional optimisation tools but demonstrates the complementary potential of reinforcement learning in the data-rich field of hydropower scheduling.},
author = {Riemer, Signe and Id, S{\o}rensen and Rosenlund, Gjert H},
doi = {10.1109/SEST48500.2020.9203208},
file = {:C\:/Users/mah/Google Drive/Documents/Mendeley-Library/Riemer, Id, Rosenlund - 2020 - Deep Reinforcement Learning for Long Term Hydropower Production Scheduling.pdf:pdf},
keywords = {Index Terms-machine learning,expert systems,hydroelectric power generation,power gener-ation economics},
title = {{Deep Reinforcement Learning for Long Term Hydropower Production Scheduling}},
url = {http://dx.doi.org/10.1109/SEST48500.2020.9203208},
year = {2020}
}
@article{Matheussen2019,
abstract = {This paper demonstrates how deep learning can be used to find optimal reservoir operating policies in hydropower river systems. The method that we propose is based on the implicit stochastic optimization (ISO) framework, using direct policy search methods combined with deep neural networks (DNN). The findings from a real-world two-reservoir hydropower system in southern Norway suggest that DNNs can learn how to map input (price, inflow, starting reservoir levels) to the optimal production pattern directly. Due to the speed of evaluating the DNN, this approach is from an operational standpoint computationally inexpensive and may potentially address the long-standing problem of high dimensionality in hydropower optimization. Further on, our method may be used as an input for decision-theoretic planning, suggesting the policy that will give the highest expected profit. The approach also permits for a broader use of pre-trained neural networks in historical reanalysis of production patterns and studies of climate change effects.},
author = {Matheussen, Bernt Viggo and Granmo, Ole Christoffer and Sharma, Jivitesh},
doi = {10.1007/978-3-030-22999-3_11},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Energy,Hydrology,Markov,Reservoir,Scheduling,Water},
pages = {110--122},
publisher = {Springer Verlag},
title = {{Hydropower optimization using deep learning}},
volume = {11606 LNAI},
year = {2019}
}
@book{sutton2018,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}